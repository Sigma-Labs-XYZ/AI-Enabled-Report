<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta
      name="description"
      content="Sigma Labs: AI-Native Consultants Report 2025"
    />
    <title>Sigma Labs: AI-Native Consultants Report</title>

    <!-- Favicon -->
    <link rel="icon" type="image/png" href="./assets/icon.png" />
    <link rel="shortcut icon" type="image/png" href="./assets/icon.png" />
    <link rel="apple-touch-icon" href="./assets/icon.png" />

    <!-- Google Fonts - Raleway -->
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Raleway:wght@300;400;500;600;700;800&display=swap"
      rel="stylesheet"
    />

    <!-- CSS -->
    <link rel="stylesheet" href="css/main.css" />

    <!-- Chart.js -->
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.1/dist/chart.umd.min.js"></script>
  </head>
  <body>
    <!-- Fixed Navigation -->
    <nav class="main-nav" id="main-nav">
      <div class="nav-container">
        <button
          class="mobile-menu-toggle"
          id="mobile-menu-toggle"
          aria-label="Toggle menu"
        >
          ☰
        </button>

        <ul class="nav-menu" id="nav-menu">
          <li><a href="#introduction" class="nav-link">Introduction</a></li>
          <li><a href="#background" class="nav-link">Background</a></li>
          <li><a href="#hypothesis" class="nav-link">Hypothesis</a></li>
          <li><a href="#methodology" class="nav-link">Methodology</a></li>
          <li><a href="#outcomes" class="nav-link">Outcomes</a></li>
          <li>
            <a href="#reflections" class="nav-link">Reflections & Conclusion</a>
          </li>
        </ul>
      </div>

      <!-- Reading Progress Indicator -->
      <div class="progress-indicator" id="progress-indicator"></div>
    </nav>

    <!-- Hero Section -->
    <section id="hero" class="hero-section">
      <div class="hero-content">
        <h1 class="hero-title">AI-Native Technologists</h1>
        <p class="hero-subtitle">
          Impact and Findings from Training LLM-Enabled Consultants
        </p>
      </div>
      <div
        class="scroll-indicator"
        onclick="document.getElementById('introduction').scrollIntoView({ behavior: 'smooth' })"
      >
        ↓
      </div>
    </section>

    <!-- Main Content -->
    <main class="main-content">
      <!-- Introduction Section -->
      <section id="introduction" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Introduction</h2>
        </div>

        <details class="collapsible-section">
          <summary>
            <div>
              <div class="collapsible-section-title">About Sigma Labs</div>
              <p class="collapsible-section-description">
                Not heard of us before? Here's a quick overview.
              </p>
            </div>
          </summary>
          <div class="collapsible-content">
            <p>
              We -
              <a href="https://www.sigmalabs.co.uk/" target="_blank"
                >Sigma Labs</a
              >
              - are a technology consulting firm specializing in
              high-performance talent solutions. We bridge the gap between
              outstanding graduates and forward-thinking organizations through
              our comprehensive approach to talent development.
            </p>

            <h4>What We Do</h4>
            <p>Our work focuses on three core pillars:</p>
            <ul class="styled-list mt-md">
              <li>
                <strong>Hiring:</strong> Recruiting exceptional graduates with
                the potential to become world-class technologists
              </li>
              <li>
                <strong>Training:</strong> Delivering industry-leading
                professional development programs that transform raw talent into
                skilled practitioners
              </li>
              <li>
                <strong>Placement:</strong> Connecting our clients with highly
                skilled software, data, and cloud consultants who can deliver
                immediate value
              </li>
            </ul>

            <h4>Key Achievements</h4>
            <ul class="styled-list mt-md">
              <li>
                <strong>Consultant Success:</strong> 82% of our clients rate our
                consultants in the top quartile of all people in their team. 94%
                of trainees who have finished our program have successfully
                secured roles in the tech industry.
              </li>
              <li>
                <strong>Certified B Corporation:</strong> Sigma Labs holds B
                Corp certification, demonstrating our commitment to balancing
                purpose and profit while meeting rigorous standards of social
                and environmental performance, accountability, and transparency
              </li>
              <li>
                <strong>Innovative Training Programs:</strong> We continuously
                evolve our training methodologies to stay ahead of industry
                trends, with this AI-Native consultant program representing our
                latest innovation in talent development
              </li>
            </ul>

            <p class="mt-md">
              Our mission is to amplify talent through exceptional training,
              enabling both our consultants and clients to thrive in an
              increasingly complex technology landscape.
            </p>
          </div>
        </details>

        <div class="section-content">
          <p class="lead">
            Between August and November 2025, Sigma Labs trained it's first
            cohort of AI-native consultants. This report summarizes key findings
            from our research into AI adoption, industry trends, performance
            metrics, and the evolving technology ecosystem.
          </p>

          <p>
            We defined "AI-Native Consultants" as professionals who have been
            trained from the outset to leverage large language models (LLMs) and
            related AI technologies as integral tools in their consulting
            practice. This contrasts with traditional consultants who may adopt
            AI tools later in their careers.
          </p>

          <p>
            Our hypothesis was that AI-Native Consultants would demonstrate
            superior performance in project delivery, problem-solving, and
            client outcomes compared to their traditionally trained peers. We
            actively worked against the risks of AI over-reliance by embedding
            several techniques to ensure critical thinking and domain expertise
            remained central to our training.
          </p>

          <div class="grid grid-2 mt-xl">
            <div class="card">
              <h3 class="card-title">Executive Summary</h3>
              <div class="card-content">
                <p>
                  By leveraging the power of LLMs, our
                  <b
                    >AI-Native Course trainees demonstrated a 21% increase in
                    project completion speed or complexity</b
                  >
                  <p>This was achieved whilst maintaining the <b>same level of quality of outcomes</b>,
                  and <b>without a decrease in knowledge retention</b></p>
                </p>
              </div>
            </div>

            <div class="card">
              <h3 class="card-title">Methodology</h3>
              <div class="card-content">
                <p>
                  We conducted an
                  <b
                    >AB testing style study over a 15-week period which involved
                    18 trainees split into two groups of 9</b
                  >. One group completed our Traditional Course, while the other
                  completed our AI-Native Course.
                </p>
                <p>
                  Both groups were assessed on project completion speed, quality
                  of outcomes, and knowledge retention through standardized
                  tests and project evaluations.
                </p>
              </div>
            </div>
          </div>
        </div>
      </section>

      <section id="background" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Background</h2>
        </div>

        <div class="section-content">
          <div class="summary-box">
            <div class="summary-box-title">Key Points</div>
            <ul>
              <li>
                GitHub Copilot (2021) marked the shift from autocomplete to true
                AI pair-programming
              </li>
              <li>
                76% of developers using or planning to use AI tools (Stack
                Overflow 2024), up from 70% in 2023
              </li>
              <li>
                Fast-moving startups report 80%+ of codebase written by AI; Big
                Tech seeing revolutionary change
              </li>
            </ul>
          </div>

          <p>
            The release of GitHub Copilot in mid-2021 marked a watershed moment
            for software development: for the first time, a large-scale model
            trained on public repositories could sit alongside a developer in
            their IDE and suggest entire functions, boilerplate, or even complex
            algorithms in real time. Powered by OpenAI’s Codex, Copilot
            demonstrated that AI could move beyond simple autocomplete and into
            a true “pair-programming” paradigm. Early adopters praised its
            ability to reduce repetitive coding tasks, speed up prototyping, and
            introduce best-practice patterns.
          </p>

          <p>
            In the years since, an ecosystem of AI co-pilot tools has emerged.
            Cursor, Tabnine, Amazon CodeWhisperer, and enterprise LLM
            integrations now vie for developers’ attention, each bringing its
            own strengths - whether tighter on-prem security, better support for
            specialised languages, or deeper integration with cloud pipelines.
            Meanwhile, chat-based assistants like ChatGPT and Anthropic’s Claude
            offer natural-language debugging, architectural guidance, and even
            test-generation features. As these co-pilots learn from private
            codebases and context, they’re shifting from generic suggestion
            engines to customisable teammates that understand a team’s coding
            conventions, security policies, and domain-specific libraries.
          </p>

          <p>
            On the horizon, we see new ‘Agentic’ tools that promise the ability
            to replace junior or mid-level technologists completely by
            empowering the AI to complete multi-step actions encompassing the
            full software development lifecycle. Development is progressing at
            pace with tools such as Devin.ai , but a proven track record to
            produce industry-standard code on large existing codebases is yet to
            be seen.
          </p>

          <p>
            The hypothesis that this document is predicated on is that AI tools
            will continue to become more powerful and companies will realise
            that without the performance gained from using it, they won’t be
            able to keep up with the speed at which their competitors can ship
            software.
          </p>

          <h4>Industry Research</h4>

          <p>
            Within start-ups (we’ve spoken to one tech lead, and one founder),
            we’ve seen a much larger uptake, with one quoting that they believe
            80%+ of their codebase has been written by AI. Most notably, this
            quote shows the dramatic uptake that has been.
          </p>

          <blockquote>
            “There is code that has been written, tested, deployed and will -
            eventually - be removed without ever having had a human see it”
          </blockquote>

          <p>
            This reinforces the sense from industry that the current suite of
            tools is most useful for greenfield projects, with limited scope,
            where moving fast is preferable to solving problems comprehensively.
          </p>

          <p>
            This rapid uptake by very early-stage start-ups can be explained by
            the forcing effect that limited resources have on small companies.
            Poor quality code is unlikely to force them to close; not having a
            product-market fit will.
          </p>

          <p>
            More widely in the industry, the
            <a
              href="https://survey.stackoverflow.co/2024/ai#sentiment-and-usage-ai-sent"
              target="_blank"
              >Stack Overflow Developer Survey 2024 stated that</a
            >
          </p>

          <blockquote>
            76% of all respondents are using or are planning to use AI tools in
            their development process this year, an increase from last year
            (70%). Many more developers are currently using AI tools this year,
            too (62% vs. 44%).
          </blockquote>

          <p>
            In the world of Big Tech, adoption within teams building the tools
            (i.e. the most obvious first adopters) is surprisingly high. Tim
            Rogers (Product Owner at Github) shared their data
            <a
              href="https://news.ycombinator.com/item?id=44031432"
              target="_blank"
              >on HackerNews</a
            >
          </p>

          <blockquote>
            So far, the agent has been used by about 400 GitHub employees in
            more than 300 our our repositories, and we've merged almost 1,000
            pull requests contributed by Copilot. [..] In the repo where we're
            building the agent, the agent itself is actually the #5 contributor
            - so we really are using Copilot coding agent to build Copilot
            coding agent [...]
          </blockquote>

          <p>
            To summarise, adoption is accelerating rapidly across all business
          </p>

          <ul class="styled-list mt-md">
            <li>
              Fast-moving start-ups have seen revolutionary change in their
              processes
            </li>
            <li>Big tech at the bleeding edge has also seen the value</li>
          </ul>
        </div>
      </section>

      <!-- AI Adoption Trends Section -->
      <section id="hypothesis" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Hypothesis</h2>
        </div>

        <div class="section-content">
          <div class="summary-box">
            <div class="summary-box-title">Key Points</div>
            <ul>
              <li>
                AI shifts bottleneck from code writing to requirements gathering
                and quality assurance (V-Bounce model)
              </li>
              <li>
                AI-native technologists must excel at prompting, stakeholder
                management, and quality assurance
              </li>
              <li>
                Companies will hire junior technologists to work at new
                bottleneck: requirements and testing
              </li>
            </ul>
          </div>

          <p>
            In the research paper titled
            <a href="https://arxiv.org/pdf/2408.03416" target="_blank"
              >'The AI-Native Software Development Lifecycle: A Theoretical and
              Practical New Methodology'</a
            >, the authors speak about a radical change in the places that take
            up the most time when producing software. This relies on the
            ‘V-Model’ of software development (see Figure 1 below), which tries
            to describe the way software is built.
          </p>

          <p>
            In this model, cheap, junior technologists are brought in to tackle
            the largest bottleneck in this system (represented by the largest
            box) - writing the code. This is not technically the hardest part of
            the problem, and if the problem has been well defined and
            structured, this should be achievable for juniors to complete with
            support.
          </p>

          <p>
            However, with the use of AI, this model would be transformed to look
            more like this - the ‘V-Bounce’ model (see Figure 2 below). In this
            new model, it is apparent that the bottleneck in this system is no
            longer writing code - which is mostly automated - but rather in the
            requirements gathering and testing phases of the project.
            <b
              >We hypothesise that one outcome of this is that companies will
              now be hiring cheap, junior technologists to work at the new
              bottleneck of production - requirements gathering and quality
              assurance.</b
            >
          </p>

          <div class="visualization-container chart-appear">
            <div class="grid grid-2">
              <div class="diagram-item">
                <img
                  src="./assets/v-model.png"
                  alt="V-Model Diagram"
                  class="diagram-image"
                />
                <p class="caption">Figure 1: V-Model of Software Development</p>
              </div>
              <div class="diagram-item">
                <img
                  src="./assets/v-bounce.png"
                  alt="V-Bounce Diagram"
                  class="diagram-image"
                />
                <p class="caption">
                  Figure 2: V-Bounce Model of Software Development, post AI
                </p>
              </div>
            </div>
          </div>
        </div>

        <div class="section-content">
          <p>
            There are, of course, many other bottlenecks in a software project -
            architecture, deployment and cross-team coordination - that aren't
            solely code-generation issues. But these will often fall outside a
            junior engineer's remit, sitting with an Architect or Tech Leads to
            work through.
          </p>

          <p>
            Our hypothesis is that junior technologist will now need to be
            highly skilled in these three areas to be effective in this new
            world:
          </p>

          <details class="collapsible-section">
            <summary>
              <div>
                <p class="collapsible-section-description">
                  1. Using AI to generate code to solve problems and maintain
                  productivity
                </p>
              </div>
            </summary>
            <div class="collapsible-content">
              <ul class="styled-list mt-md">
                <li>
                  Write a concise prompt that specifies the programming
                  language, input/output formats, and any edge-case
                  requirements.
                </li>
                <li>
                  Provide relevant context (existing code, data schemas,
                  dependencies) so the AI generates code that fits the project.
                </li>
                <li>
                  Compare multiple AI outputs, choose the best one, and refine
                  the prompt to address missing features or bugs.
                </li>
                <li>
                  Review every line of AI-generated code for correctness,
                  performance, and security before merging.
                </li>
              </ul>
            </div>
          </details>

          <details class="collapsible-section">
            <summary>
              <div>
                <p class="collapsible-section-description">
                  2. Working with stakeholders to ensure they're solving the
                  right problem
                </p>
              </div>
            </summary>
            <div class="collapsible-content">
              <ul class="styled-list mt-md">
                <li>
                  Schedule and lead meetings to capture business
                  goals, constraints, and success metrics.
                </li>
                <li>
                  Turn stakeholder input into concise user stories, acceptance
                  criteria, and manual decomposition before prompting AI.
                </li>
                <li>
                  Provide regular, transparent updates on progress, highlighting
                  both AI-generated work and manual changes.
                </li>
                <li>
                  Document edge-cases, data-privacy needs, and potential AI
                  hallucinations so risks are visible from day one.
                </li>
              </ul>
            </div>
          </details>

          <details class="collapsible-section">
            <summary>
              <div>
                <p class="collapsible-section-description">
                  3. Ensuring high quality output through comprehensive user testing and
                  validation
                </p>
              </div>
            </summary>
            <div class="collapsible-content">
              <ul class="styled-list mt-md">
                <li>
                  Define clear test scenarios (unit, integration, end-to-end)
                  before asking AI to scaffold tests.
                </li>
                <li>
                  Prompt AI tools to generate initial test cases, then refine or
                  extend those tests to cover edge cases.
                </li>
                <li>
                  Automate QA checks in CI/CD pipelines so every commit
                  undergoes the same rigorous validation.
                </li>
                <li>
                  Track and report test coverage, code quality metrics, and
                  security findings to the team.
                </li>
              </ul>
            </div>
          </details>
        </div>
      </section>

      <!-- Industry Analysis Section -->
      <section id="methodology" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Methodology</h2>
          <p class="section-subtitle">
            Our approach to training AI-Native Consultants
          </p>
        </div>

        <p class="lead">
          With the skill set of a junior technologist shifting from code writing
          to requirements gathering and quality assurance, our training
          methodology needed to adapt accordingly. We developed a new AI-Native
          training program that emphasised these skills while still ensuring
          strong foundational coding abilities.
        </p>

        <p>
          We understood that the core challenge with training AI-Native was that
          of over-reliance on AI tools. If trainees simply used AI to generate
          code for them, they would not develop the critical thinking and
          problem-solving skills needed to be effective technologists. To
          address this, we embedded several techniques into our training program
          to ensure that trainees remained active participants in the
          development process.
        </p>

        <details class="collapsible-section">
          <summary>
            <div>
              <div class="collapsible-section-title">
                1. End-to-End Project-Based Learning
              </div>
              <p class="collapsible-section-description">
                Full project lifecycle training from requirements gathering to
                production support
              </p>
            </div>
          </summary>
          <div class="collapsible-content">
            <p>
              Currently, we provide trainees with a fully scoped-out case study
              in which all requirements and discovery have already been
              completed. Each cohort works through a sequence of well-defined
              tasks - from data ingestion to transformation to basic front-end
              display- chunked into step-by-step challenges. This model ensures
              focus on coding and tool usage but omits the critical early phases
              of stakeholder engagement, requirements gathering and solution
              design. The reason we do this is that this is mostly where they'd
              be spending their time as Junior Technologists - writing code.
            </p>

            <p>In this new 'End-to-End' style, trainees will also</p>

            <ul class="styled-list mt-md">
              <li>
                Conduct Requirement Gathering from clients directly. ('Clients'
                are role played by Coaches)
              </li>
              <li>Run check-ins with clients to get feedback</li>
              <li>
                Design complete architecture solutions (where they would
                previously have been given a solution)
              </li>
              <li>
                Compare and contrast architecture solutions to decide on the
                best solution
              </li>
              <li>
                Ensure all requirements have been met during project sign-off
                with a client
              </li>
            </ul>

            <p>
              What this means in practice is that
              <b
                >all Consultants can work fully across the project, from
                requirements gathering through to supporting in production</b
              >
            </p>
          </div>
        </details>

        <details class="collapsible-section">
          <summary>
            <div>
              <div class="collapsible-section-title">
                2. Prompt → Explain → Apply
              </div>
              <p class="collapsible-section-description">
                Active learning loop ensuring deep understanding of AI-generated
                code
              </p>
            </div>
          </summary>
          <div class="collapsible-content">
            <p>
              The current learning to code loop might look like
              "Understand-Build-Test". First, the trainee has to understand the
              problem, break it down into steps, break that down into actionable
              pieces of code, build it, and then test what they've built.
              Through this process, they will (hopefully) build a deep
              understanding of the tools they're using by exploring the
              capabilities of the tools. They will iterate through maybe wrong
              or wrong-ish solutions before ultimately landing on one that
              works, often through a process of trial and error.
            </p>
            <p>
              The approach is less effective when the AI may generate an exact
              solution for them first time. Unless we're careful, they will
              never be exposed to all the bad solutions before they end up at
              the good one - they'll just be given the good one.
            </p>
            <p>
              The "Prompt → Explain → Apply" loop keeps trainees active
              technologists rather than passive consumers of AI output by
              enforcing three tight phases on every task
            </p>

            <p>
              What this means in practice is that
              <b
                >all Consultants fully understand what they're doing, even when
                LLMs are doing the work for them</b
              >
            </p>
          </div>
        </details>

        <details class="collapsible-section">
          <summary>
            <div>
              <div class="collapsible-section-title">
                3. Project Defence & Presentations
              </div>
              <p class="collapsible-section-description">
                Weekly presentations to demonstrate true understanding of
                AI-assisted work
              </p>
            </div>
          </summary>
          <div class="collapsible-content">
            <p>
              In an AI-Native world, having completed the task is no longer a
              good judge of understanding. The AI may have done the work for
              you, after all. Instead, we need to ensure that trainees can
              demonstrate deep understanding of the work they've done through a
              process of project defence and presentations.
            </p>

            <p>
              At least once a week, every consultant is asked to present their
              project and their code in front of a Senior Coach.
            </p>

            <p>The result of this is</p>

            <ul class="styled-list mt-md">
              <li>
                Guarantees Comprehension: You can't fake your way through a live
                Q&A - defenders must truly understand every line.
              </li>
              <li>
                Reinforces Critical Reading: Critics learn to combine AI
                suggestions with human judgement, practising both tool-use and
                code review skills.
              </li>
              <li>
                Cultivates Accountability: The whole team sees when AI misses
                something or a trainee misunderstands their own code, driving
                continuous improvement.
              </li>
            </ul>
          </div>
        </details>

        <details class="collapsible-section">
          <summary>
            <div>
              <div class="collapsible-section-title">4. AI Best Practice</div>
              <p class="collapsible-section-description">
                Security, compliance, and data privacy guardrails for
                AI-generated code
              </p>
            </div>
          </summary>
          <div class="collapsible-content">
            <div class="summary-box">
              <div class="summary-box-title">Key Points</div>
              <ul>
                <li>
                  Secure-by-Design Coding: Threat modeling, vulnerability
                  scanning, and AI pitfall checklists
                </li>
                <li>
                  Licence & IP Compliance: Automated scanning to prevent
                  restrictive licence violations
                </li>
                <li>
                  Data Privacy & PII Protection: Policies and tools to prevent
                  sensitive data leaks to public LLMs
                </li>
              </ul>
            </div>

            <p>
              An "AI Best Practice" module equips engineers with the principles,
              patterns and automated guardrails needed to safely harness
              generative code tools—specifically addressing the security,
              licence/IP and data-privacy risks they introduce.
            </p>

            <ul class="styled-list mt-md">
              <li>
                <strong>Secure-by-Design Coding</strong>
                <ul class="styled-list mt-xs">
                  <li>
                    Teach secure prompt patterns (e.g. default to input
                    sanitisation) and threat-model AI outputs before merging.
                  </li>
                  <li>
                    Lab: Use static-analysis and vulnerability scanners as CI gates on every AI-generated snippet.
                  </li>
                  <li>
                    Provide a checklist of common AI pitfalls (open ports,
                    disabled TLS checks, unsanitised file paths) and remediation
                    snippets.
                  </li>
                </ul>
              </li>

              <li>
                <strong>Licence &amp; IP Compliance</strong>
                <ul class="styled-list mt-xs">
                  <li>
                    Explain the difference between permissive and copyleft
                    licences and the dangers of accepting GPL-style code
                    verbatim.
                  </li>
                  <li>
                    Automate licence scanning in CI (FOSSA, SPDX checks) to flag
                    any third-party snippets that carry restrictive terms.
                  </li>
                  <li>
                    Supply templates for standard attribution headers and a
                    "safe-prompt" library that avoids licence-bound examples.
                  </li>
                </ul>
              </li>

              <li>
                <strong>Data Privacy &amp; PII Protection</strong>
                <ul class="styled-list mt-xs">
                  <li>
                    Enforce policies against sending sensitive data or
                    proprietary code to public LLMs.
                  </li>
                  <li>
                    Demonstrate how to scrub or anonymise inputs (redacting
                    names, IDs) and use enterprise-grade, on-prem or
                    private-endpoint models.
                  </li>
                  <li>
                    Lab: Simulate a GDPR breach by pasting PII into a public API
                    and then apply scripts to detect &amp; remove leaks.
                  </li>
                </ul>
              </li>
            </ul>

            <p class="mt-md">
              By combining hands-on exercises with automated CI-gated checks,
              ready-made checklists and real-world examples, this module ensures
              trainees can confidently generate, vet and deploy AI-assisted code
              without exposing their organisation to security, legal or
              compliance failures.
            </p>
          </div>
        </details>
      </section>

      <!-- Performance Metrics Section -->
      <section id="outcomes" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Outcomes</h2>
          <p class="section-subtitle">
            Impact and analysis of the AI-Native training program
          </p>
        </div>

        <div class="summary-box">
          <div class="summary-box-title">Key Points</div>
          <ul>
            <li>
              AI-Native consultants completed coursework 19% faster (29.2 vs
              36.1 hours) while maintaining high understanding scores
            </li>
            <li>
              Group projects showed significant productivity multiplier:
              AI-Native consultants delivered more complex, feature-rich
              applications in the same timeframe
            </li>
            <li>
              Consistently higher interview performance across all formats, with
              8.1/10 satisfaction and +33% self-reported productivity gains
            </li>
          </ul>
        </div>

        <div class="section-content">
          <h4>Impact on Productivity</h4>
          <h5>Independent Learning</h5>

          <p>
            To assess the impact of AI-Native training on independent learning
            speed, we compared the time taken by both traditional and AI-enabled
            training groups to the coursework of our programme. The modules
            covered new technologies and concepts not previously encountered by
            either group. Additionally, the AI-enabled group were given less
            details for the projects to complete, requiring them to research
            more independently.
          </p>

          <p>
            What we found, was that by the time that trainees were fully ramped
            in terms of AI tooling (i.e. using generative and agentic coding and
            LLMs regularly) they were able to complete the coursework to same
            standard, to a high level of understanding, in 19% less time on
            average.
          </p>

          <div class="stats-callout-container">
            <div class="stat-callout-box">
              <div class="stat-callout-label">
                Completion Time for AI-Natives
              </div>
              <div class="stat-callout-number">-19%</div>
              <div class="stat-callout-description">
                29.2 hours vs 36.1 hours average time to complete coursework
              </div>
            </div>

            <div class="stat-callout-box">
              <div class="stat-callout-label">
                Average Score in Project Understanding
              </div>
              <div class="stat-callout-number">8.4/10</div>
              <div class="stat-callout-description">
                Assessed by Senior Coaches during Project Defence sessions
              </div>
            </div>

            <div class="stat-callout-box">
              <div class="stat-callout-label">
                Average Score in Code Defence
              </div>
              <div class="stat-callout-number">7.2/10</div>
              <div class="stat-callout-description">
                Assessed by Senior Coaches across 'Justification', 'Correctness'
                and 'Depth' of answer
              </div>
            </div>
          </div>

          <h5>Group Projects</h5>

          <p>
            To measure the impact of AI-Native training on productivity, we
            compared the Group Project outputs between traditional and
            AI-enabled training groups. Both groups worked on the same project
            briefs with the same complexity and timeframes. The visual
            comparison below demonstrates the significant difference in output
            and complexity achieved by AI-enabled consultants.
          </p>

          <div class="visualization-container chart-appear mt-xl">
            <h5>Traditional Training Projects</h5>
            <p class="caption mb-md">
              Projects completed by consultants using traditional training
              methods
            </p>
            <div class="grid grid-2 mb-xl">
              <div class="diagram-item">
                <img
                  src="./assets/projects/trad_group1_1.png"
                  alt="Traditional Training - Group 1 Project"
                  class="diagram-image"
                />
                <p class="caption">
                  Traditional Group 1 (taken from Project Presentation)
                </p>
              </div>
              <div class="diagram-item">
                <img
                  src="./assets/projects/trad_group2_1.png"
                  alt="Traditional Training - Group 2 Project"
                  class="diagram-image"
                />
                <p class="caption">Traditional Group 2</p>
              </div>
            </div>

            <h5 class="mt-xl">AI-Native Training Projects</h5>
            <p class="caption mb-md">
              Projects completed by consultants using AI-Native training methods
            </p>
            <div class="grid grid-2">
              <div class="diagram-item">
                <img
                  src="./assets/projects/ai_group1_1.png"
                  alt="AI-Native Training - Group 1 Project 1"
                  class="diagram-image"
                />
                <p class="caption">
                  AI-Native Group 1 (taken from Project Presentation)
                </p>
              </div>
              <div class="diagram-item">
                <img
                  src="./assets/projects/ai_group2_1.png"
                  alt="AI-Native Training - Group 2 Project 1"
                  class="diagram-image"
                />
                <p class="caption">AI-Native Group 2</p>
              </div>
            </div>
          </div>

          <p>
            A visual comparison demonstrates that AI-Native consultants not only
            completed more projects within the same timeframe but also tackled
            projects of greater complexity and scope. This represents a
            significant productivity multiplier while maintaining code quality
            and architectural standards.
          </p>

          <div class="grid grid-2 mt-xl">
            <div class="visualization-container chart-appear">
              <div class="chart-wrapper">
                <canvas id="linesOfCodeChart"></canvas>
              </div>
              <p class="caption mt-md">
                Total lines of code delivered by each group. AI teams produced
                significantly more code volume, with Group 2 delivering 6.5x more
                lines than their traditional counterpart.
              </p>
            </div>

            <div class="visualization-container chart-appear">
              <div class="chart-wrapper">
                <canvas id="complexityChart"></canvas>
              </div>
              <p class="caption mt-md">
                Average cyclomatic complexity per function. AI teams maintained
                similar or slightly higher complexity levels, indicating more
                sophisticated logic implementation.
              </p>
            </div>
          </div>

          <h4>Consultant Performance & Quality</h4>

          <p>
            To evaluate the effectiveness of our AI-Native training approach, we
            conducted a series of standardized interview assessments comparing
            AI-Enabled consultants against those trained using traditional
            methods. The results demonstrate consistently higher performance
            across all interview formats.
          </p>

          <div class="visualization-container chart-appear">
            <div class="chart-wrapper">
              <canvas id="interviewPerformanceChart"></canvas>
            </div>
          </div>

          <h4>Consultant Feedback & Self-Reflection</h4>

          <p>
            We collected feedback from consultants who completed the AI-Enabled
            training program. Their responses provide valuable insights into the
            effectiveness of the approach and areas for improvement.
          </p>

          <div class="stats-callout-container">
            <div class="stat-callout-box">
              <div class="stat-callout-label">Overall Satisfaction</div>
              <div class="stat-callout-number">8.1/10</div>
              <div class="stat-callout-description">
                Average happiness rating with 75% scoring 8+
              </div>
            </div>

            <div class="stat-callout-box">
              <div class="stat-callout-label">Productivity Gain</div>
              <div class="stat-callout-number">+33%</div>
              <div class="stat-callout-description">
                Self-reported average performance impact
              </div>
            </div>

            <div class="stat-callout-box">
              <div class="stat-callout-label">Learning Effect</div>
              <div class="stat-callout-number">+21%</div>
              <div class="stat-callout-description">
                Self-reported average impact on learning
              </div>
            </div>
          </div>

          <h5 class="mt-xl">What Consultants Loved</h5>

          <blockquote>
            "I liked the fact that I was able to use advanced AI's in a
            professional setting and really scale up the level and quality of my
            work"
          </blockquote>

          <blockquote>
            "Significantly speeds up gaining familiarity and general mastery
            over new technology tools, more efficient than reviewing over docs
            and simplifies learning through summary"
          </blockquote>

          <blockquote>
            "I liked most the deeper understanding gained from code defence, I
            feel this took me beyond simply doing to understanding AWS more
            deeply which is so valuable in industry"
          </blockquote>

          <p>Key positive themes that emerged:</p>
          <ul class="styled-list mt-md">
            <li>
              <strong>Immediate Support:</strong> Consultants valued getting
              instant explanations and debugging help, accelerating their
              workflow
            </li>
            <li>
              <strong>Tool Exposure:</strong> Exposure to diverse AI tools
              (Claude's generative and agentic versions, Copilot) expanded their
              technical toolkit
            </li>
            <li>
              <strong>Deeper Understanding:</strong> Code defences forced deep
              comprehension, taking consultants beyond surface-level completion
            </li>
            <li>
              <strong>Learning Efficiency:</strong> AI as a learning tool proved
              highly effective, with 3 consultants reporting 50-70% learning
              gains
            </li>
          </ul>

          <h5 class="mt-xl">Areas for Improvement</h5>

          <p>
            Consultants also identified several areas where the program could be
            enhanced:
          </p>

          <ul class="styled-list mt-md">
            <li>
              <strong>Agentic AI Caution:</strong> Concerns about over-reliance
              on agentic AI tools (like Claude Code), with recommendations to
              introduce them later in training or use them more sparingly
            </li>
            <li>
              <strong>Assessment & Feedback:</strong> Need for clearer
              assessment criteria and more consistent feedback, particularly
              around gauging true understanding vs AI-generated work
            </li>
          </ul>

          <div class="summary-box mt-xl">
            <div class="summary-box-title">Key Insight</div>
            <p>
              While consultants overwhelmingly appreciated the productivity and
              learning benefits of AI tools, they expressed thoughtful concerns
              about maintaining deep understanding and avoiding over-reliance.
              This validates our emphasis on code defences and structured
              learning phases, while highlighting opportunities to refine the
              timing and intensity of assessments.
            </p>
          </div>
        </div>
      </section>

      <!-- AI Ecosystem Section -->
      <section id="reflections" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Reflections & Conclusion</h2>
          <p class="section-subtitle">Insights from our journey so far</p>
        </div>

        <div class="section-content">
          <p>
            The shift to AI-Native technologists represents a fundamental change
            in how we train and deploy junior engineers. By focusing on
            requirements gathering, stakeholder management, and quality
            assurance, we prepare consultants for the new bottlenecks in
            software development.
          </p>

          <p>
            Our AI-Native training program has demonstrated significant gains in
            productivity and quality, with consultants completing work faster
            while maintaining high standards. The emphasis on active learning,
            code defences, and AI best practices ensures that consultants
            develop deep understanding rather than superficial reliance on AI
            tools.
          </p>

          <p>
            As AI continues to evolve, so too must our training methodologies.
            We are committed to refining our approach based on feedback and
            outcomes, ensuring that our consultants remain at the forefront of
            this transformative era in technology.
          </p>
        </div>
      </section>

      <section id="reflections" class="content-section observe-fade">
        <div class="section-header">
          <h2 class="section-title">Interested?</h2>
        </div>

        <div class="section-content">
          <p>
            Want to employ our AI-Native consultants or learn more about our AI
            -Native training program? </p>

          <p>Get in touch at
            <a href="mailto:clients@sigmalabs.co.uk">clients@sigmalabs.co.uk</a>
          </p></p>
        </div>
      </section>
    </main>

    <!-- Footer -->
    <footer class="main-footer">
      <p>&copy; 2025 Sigma Labs. All rights reserved.</p>
      <p class="mt-sm text-xs">Data visualizations powered by Chart.js</p>
    </footer>

    <!-- Global Tooltip -->
    <div id="tooltip" class="tooltip"></div>

    <!-- JavaScript Modules -->
    <script type="module" src="js/main.js"></script>
  </body>
</html>
